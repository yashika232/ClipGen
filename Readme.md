# ğŸ¬ Video Synthesis Pipeline

> **AI-powered talking head video generation with production-ready REST API**

A complete video synthesis pipeline that transforms text scripts and face images into professional talking head videos using state-of-the-art AI models including XTTS voice cloning, SadTalker lip-sync, and Real-ESRGAN enhancement.

## âœ¨ Key Features

- **ğŸ—£ï¸ Voice Cloning**: Natural voice synthesis using XTTS technology
- **ğŸ‘¤ Face Animation**: Realistic lip-sync and facial expressions with SadTalker
- **ğŸ¥ Video Enhancement**: AI-powered upscaling with Real-ESRGAN
- **ğŸŒ REST API**: Production-ready Flask API with WebSocket support
- **ğŸ‘¥ Multi-User**: Session-based isolation and concurrent processing
- **âš¡ Real-Time**: Live progress updates via WebSocket
- **ğŸ”’ Secure**: File validation, virus scanning, and resource limits

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.8+ required
python --version

# Install system dependencies (macOS)
brew install ffmpeg libmagic

# Install system dependencies (Ubuntu)
sudo apt-get update
sudo apt-get install ffmpeg libmagic1 clamav clamav-daemon
```

### Installation
```bash
# Clone the repository
git clone https://github.com/your-username/video-synthesis-pipeline.git
cd video-synthesis-pipeline

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
export GEMINI_API_KEY="your_gemini_api_key"
export PRODUCTION_MODE="true"
```

### Start the API Server
```bash
# Start the production API server
python start_api_server.py

# API available at: http://localhost:5000
# WebSocket at: ws://localhost:5000/socket.io
# Health check: http://localhost:5000/health
```

## ğŸ“š API Usage

### Create Session & Generate Video
```python
import requests
import socketio

# Create session
response = requests.post('http://localhost:5000/session/create', 
    json={'user_id': 'user123'})
session_id = response.json()['session_id']

# Upload face image
with open('face.jpg', 'rb') as f:
    files = {'file': f}
    data = {'session_id': session_id}
    requests.post('http://localhost:5000/upload/face', 
        files=files, data=data)

# Upload audio or start with text
requests.post('http://localhost:5000/process/start',
    json={
        'session_id': session_id,
        'script_text': 'Hello, this is my talking head video!'
    })

# Real-time progress via WebSocket
sio = socketio.Client()
sio.connect('http://localhost:5000')
sio.emit('subscribe_progress', {'session_id': session_id})

@sio.on('progress_update')
def on_progress(data):
    print(f"Progress: {data['progress_percent']}% - {data['message']}")
```

### JavaScript/React Integration
```javascript
// Frontend integration example
const socket = io('ws://localhost:5000');

// Create session
const response = await fetch('/session/create', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({user_id: 'user123'})
});
const {session_id} = await response.json();

// Track progress
socket.emit('subscribe_progress', {session_id});
socket.on('progress_update', (data) => {
    console.log(`${data.progress_percent}%: ${data.message}`);
});

// Start processing
await fetch('/process/start', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        session_id: session_id,
        script_text: 'Your video script here'
    })
});
```

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â—„â”€â”€â”€â”¤  Flask API      â”‚â—„â”€â”€â”€â”¤ Session Manager â”‚
â”‚   Application   â”‚    â”‚  + WebSocket    â”‚    â”‚ + File Security â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   AI Pipeline       â”‚
                    â”‚                     â”‚
                    â”‚  Text â†’ XTTS        â”‚
                    â”‚    â†“                â”‚
                    â”‚  Audio â†’ SadTalker  â”‚
                    â”‚    â†“                â”‚
                    â”‚  Video â†’ Real-ESRGANâ”‚
                    â”‚    â†“                â”‚
                    â”‚  Enhanced Video     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | System health and status |
| `GET` | `/capabilities` | Production capabilities |
| `POST` | `/session/create` | Create user session |
| `GET` | `/session/{id}/status` | Get session status |
| `POST` | `/upload/face` | Upload face image |
| `POST` | `/upload/audio` | Upload audio file |
| `POST` | `/process/start` | Start video generation |
| `GET` | `/outputs/{session_id}` | List generated files |
| `GET` | `/download/{session_id}/{filename}` | Download files |
| `POST` | `/cleanup` | Manual cleanup |

## ğŸ› ï¸ Development

### Environment Setup
The pipeline uses separate conda environments for different AI models:

```bash
# Required conda environments
conda create -n xtts_voice_cloning python=3.9
conda create -n sadtalker python=3.8  
conda create -n realesrgan_real python=3.9
conda create -n video-audio-processing python=3.9
```

### Running Tests
```bash
# Production readiness tests
python test_production_video_generation.py

# API endpoint tests  
python test_api_endpoints.py

# Session management tests
python test_session_management.py
```

### Frontend Development
```bash
# Terminal 1: Start API server
python frontend_api_websocket.py

# Terminal 2: Start your frontend application
cd genify-dashboard-verse-main
npm install
npm run dev

# Terminal 3: Test API endpoints
python test_api_endpoints.py
```

## ğŸ“ Project Structure

```
video-synthesis-pipeline/
â”œâ”€â”€ ğŸ“„ README.md                    # This file
â”œâ”€â”€ ğŸ“¦ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸš€ start_api_server.py          # Quick start script
â”œâ”€â”€ ğŸŒ frontend_api_websocket.py    # Main API server
â”œâ”€â”€ ğŸ§ª test_*.py                    # Test suites
â”‚
â”œâ”€â”€ NEW/                            # Core production system
â”‚   â”œâ”€â”€ core/                       # Production managers
â”‚   â”‚   â”œâ”€â”€ production_mode_manager.py
â”‚   â”‚   â”œâ”€â”€ concurrent_session_manager.py
â”‚   â”‚   â”œâ”€â”€ realtime_progress_manager.py
â”‚   â”‚   â””â”€â”€ secure_file_validator.py
â”‚   â””â”€â”€ video_outputs/              # Generated content
â”‚
â”œâ”€â”€ stages/                         # Pipeline stages
â”‚   â”œâ”€â”€ stage0a_voice_synthesis.py
â”‚   â”œâ”€â”€ stage2_face.py
â”‚   â”œâ”€â”€ stage3_lipsync.py
â”‚   â””â”€â”€ stage4_enhance.py
â”‚
â”œâ”€â”€ genify-dashboard-verse-main/    # React frontend
â”œâ”€â”€ datasets/                       # Sample data
â”œâ”€â”€ configs/                        # Configuration files
â””â”€â”€ requirements/                   # Detailed requirements
```

## âš™ï¸ Configuration

### Environment Variables
```bash
# Required
export GEMINI_API_KEY="your_gemini_api_key"
export PRODUCTION_MODE="true"

# Optional
export MAX_CONCURRENT_SESSIONS="5"
export SESSION_TIMEOUT_HOURS="2"
export MAX_FILE_SIZE_MB="50"
export ENABLE_VIRUS_SCANNING="true"
```

### Performance Settings
- **Processing Time**: ~4-5 minutes per video
- **Memory Usage**: 4-8GB during processing
- **Concurrent Sessions**: 5 (configurable)
- **File Size Limit**: 50MB per upload
- **Supported Formats**: JPG, PNG, GIF, BMP | WAV, MP3, FLAC, OGG

## ğŸ”’ Security Features

- âœ… **File Validation**: Multi-layer file type and content verification
- âœ… **Virus Scanning**: Optional ClamAV integration
- âœ… **Session Isolation**: Complete user session separation
- âœ… **Resource Limits**: Memory and processing constraints
- âœ… **Input Sanitization**: Secure file handling and path validation
- âœ… **CORS Configuration**: Cross-origin request management

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Guidelines
- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation for API changes
- Ensure all tests pass before submitting

## ğŸ“Š Performance & Monitoring

### Health Check
```bash
# Check system status
curl http://localhost:5000/health

# Expected response
{
    "healthy": true,
    "production_ready": true,
    "memory_usage_percent": 45.2,
    "active_sessions": 2,
    "system_load": "normal"
}
```

### Resource Monitoring
```bash
# Monitor system resources
curl http://localhost:5000/health | jq '.memory_usage_percent'

# Trigger cleanup if needed
curl -X POST http://localhost:5000/cleanup
```

## ğŸ› Troubleshooting

### Common Issues

**Q: "Module not found" errors during startup**
```bash
# Install missing dependencies
pip install -r requirements.txt

# Check conda environments
conda env list
```

**Q: "Memory limit exceeded" during processing**
```bash
# Reduce concurrent sessions
export MAX_CONCURRENT_SESSIONS="2"

# Or trigger manual cleanup
curl -X POST http://localhost:5000/cleanup
```

**Q: WebSocket connection fails**
```bash
# Check if port 5000 is available
lsof -i :5000

# Restart the API server
python start_api_server.py
```

For more detailed troubleshooting, see `nonuseful/debug_legacy/legacy_docs/PRODUCTION_README.md`

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **SadTalker**: Lip-sync and facial animation technology
- **XTTS**: Advanced text-to-speech synthesis
- **Real-ESRGAN**: AI-powered video enhancement
- **OpenCV**: Computer vision processing
- **Flask**: Web framework for API development

## ğŸ“ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/your-username/video-synthesis-pipeline/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-username/video-synthesis-pipeline/discussions)
- ğŸ“§ **Email**: support@yourproject.com

---

**Ready to create amazing talking head videos?** ğŸš€

```bash
# Get started in 3 commands
git clone https://github.com/your-username/video-synthesis-pipeline.git
cd video-synthesis-pipeline && pip install -r requirements.txt
python start_api_server.py
```

*Built with â¤ï¸ using AI and modern web technologies*# video-synthesis-pipeline-copy
# video-synthesis-pipeline-copy
